import numpy as np

# Функція активації (сигмоїда)
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Похідна функції активації
def sigmoid_derivative(x):
    return x * (1 - x)

# Вхідні дані (вхідні вектори для кожної букви)
X = np.array([[0, 0, 1, 1, 1, 1, 0, 0,  # 'А'
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0],

              [0, 1, 1, 1, 1, 1, 1, 0,  # 'Б'
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 1, 1, 1, 1, 0, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 0, 0],
              
              [0, 1, 1, 1, 1, 1, 0, 0,  # 'В'
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 0, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 0, 0],
              
              [0, 1, 1, 1, 1, 1, 1, 0,  # 'Г'
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0],
              
              [0, 1, 1, 1, 1, 1, 1, 0,  # 'Д'
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 0, 0, 0, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 1, 0,
               1, 0, 0, 0, 0, 0, 0, 1,
               1, 0, 0, 0, 0, 0, 0, 1],
              
              [0, 1, 1, 1, 1, 1, 1, 0,  # 'Е'
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 1, 1, 1, 1, 1, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 1, 1, 1, 1, 1, 0],
              
              [0, 0, 0, 1, 1, 1, 1, 0,  # 'Є'
               0, 0, 1, 0, 0, 0, 0, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 1, 1, 1, 1, 1, 1, 0,
               0, 1, 0, 0, 0, 0, 0, 0,
               0, 0, 1, 0, 0, 0, 0, 0,
               0, 0, 0, 1, 1, 1, 1, 0],
              
              [1, 0, 0, 1, 1, 0, 0, 1,  # 'Ж'
               0, 1, 0, 1, 1, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 0, 0,
               1, 1, 1, 1, 1, 1, 1, 1,
               0, 0, 1, 1, 1, 1, 0, 0,
               0, 1, 0, 1, 1, 0, 1, 0,
               1, 0, 0, 1, 1, 0, 0, 1],
              
              [0, 1, 1, 1, 1, 1, 0, 0,  # 'З'
               0, 0, 0, 0, 0, 0, 1, 0,
               0, 0, 0, 0, 0, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 0, 0,
               0, 0, 0, 0, 0, 0, 1, 0,
               0, 0, 0, 0, 0, 0, 1, 0,
               0, 1, 1, 1, 1, 1, 0, 0]
              
             ])

# Вихідні дані (бажані відповіді для кожної букви)
desired_outputs = np.array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 'А'
                            [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # 'Б'
                            [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # 'В'
                            [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # 'Г'
                            [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # 'Д'
                            [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],  # 'Е'
                            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],  # 'Є'
                            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # 'Ж'
                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],  # 'З'
                            ]) 

# Ініціалізація вагових коефіцієнтів зі зміненою розмірністю
np.random.seed(1)
synaptic_weights = 0.7 * np.random.randn(56, 10) # Змінена розмірність вагових коефіцієнтів і використання нормального розподілу

# Коефіцієнт швидкості навчання
learning_rate = 0.3

# Кількість ітерацій для навчання
epochs = 10000

# Лічильник для кількості ітерацій
iteration_counter = 0

# Навчання персептрона
for epoch in range(epochs):
    for i in range(len(X)):
        # Прямий прохід
        input_layer = X[i]
        output = sigmoid(np.dot(input_layer, synaptic_weights))
        
        # Різниця між бажаним вихідом і фактичним вихідом
        error = (desired_outputs[i] - output)

        # Оновлення вагових коефіцієнтів і нейронного зміщення (дельта-правила)
        delta_weights = learning_rate * np.outer(input_layer, error)
        synaptic_weights += delta_weights
        
        # Інкрементуємо лічильник ітерацій
        iteration_counter += 1

    # Якщо мережа досягла великої точності, можна завершити навчання раніше
    if np.mean(np.abs(error)) < 0.1:
        print(f"Learning done after {iteration_counter} iteration")
        break


ukrainian_alphabet = 'АБВГДЕЄЖЗ'

for i in range(len(X)):
    input_test = X[i]
    output_test = sigmoid(np.dot(input_test, synaptic_weights))
    weights_for_letter = synaptic_weights[:, i]
    bias_for_letter = synaptic_weights[-1, i]  # Останній рядок - нейронне зміщення
    
    # Округлюємо вихід та ваги до 4 знаків після коми
    output_rounded = np.round(output_test, 3)
    weights_rounded = np.round(weights_for_letter, 3)
    bias_rounded = np.round(bias_for_letter, 3)
    
    letter = ukrainian_alphabet[i]
    
    print(f"Letter {letter}:")
    print("Output:")
    print(output_rounded)
 #   print("Weights:")
  #  print(weights_rounded)
    print("Bias:")
    print(bias_rounded)
    print("\n")
    print(f"Learning done after {iteration_counter} iteration")




